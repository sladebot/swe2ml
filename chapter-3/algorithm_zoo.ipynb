{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": [
    "# Chapter 3: The Algorithm Zoo ü¶Å\n",
    "\n",
    "Welcome to the Algorithm Zoo! Just like you pick the right data structure for the job (ArrayList vs HashMap vs Tree), you pick the right ML algorithm.\n",
    "\n",
    "This notebook covers:\n",
    "1. **Linear Regression** ‚Äî The Array (simple, fast, rigid)\n",
    "2. **Decision Trees** ‚Äî The If/Else Block (interpretable, prone to overfitting)\n",
    "3. **Random Forests** ‚Äî The Distributed System (robust, best default)\n",
    "\n",
    "Each section includes **interactive visualizations** to build intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports for the entire notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set a clean style for all plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section1-title",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Linear Regression (The Array)\n",
    "\n",
    "**The Concept**: Draw a straight line through the data.\n",
    "\n",
    "**SWE Analogy**: Like an **Array**‚Äîextremely fast and simple, but rigid. If your data isn't linear, it fails.\n",
    "\n",
    "Let's visualize what \"fitting a line\" actually means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-linreg-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Generate synthetic house price data\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# Square footage (1000 - 3000 sqft)\n",
    "sqft = np.random.uniform(1000, 3000, n_samples)\n",
    "\n",
    "# Price = base + (price_per_sqft * sqft) + noise\n",
    "# Realistic: $100/sqft + $50k base\n",
    "price = 50000 + 100 * sqft + np.random.normal(0, 20000, n_samples)\n",
    "\n",
    "# Reshape for sklearn\n",
    "X = sqft.reshape(-1, 1)\n",
    "y = price\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-linreg-fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# The \"learned\" parameters\n",
    "print(f\"Learned Formula: Price = ${lr_model.intercept_:,.0f} + ${lr_model.coef_[0]:.2f} √ó SqFt\")\n",
    "print(f\"\\nInterpretation: Base price ~${lr_model.intercept_:,.0f}, plus ~${lr_model.coef_[0]:.0f} per square foot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-linreg-viz-title",
   "metadata": {},
   "source": [
    "### Visualization 1: The Fitted Line\n",
    "This is what \"training\" looks like‚Äîfinding the line that best fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-linreg-viz1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: The fitted line\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(X_train, y_train, alpha=0.6, c='steelblue', label='Training Data', edgecolors='white')\n",
    "ax1.scatter(X_test, y_test, alpha=0.6, c='coral', label='Test Data', edgecolors='white')\n",
    "\n",
    "# Draw the regression line\n",
    "x_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "y_line = lr_model.predict(x_line)\n",
    "ax1.plot(x_line, y_line, 'k-', linewidth=2, label='Fitted Line')\n",
    "\n",
    "ax1.set_xlabel('Square Footage')\n",
    "ax1.set_ylabel('House Price ($)')\n",
    "ax1.set_title('Linear Regression: Fitting a Line Through Data')\n",
    "ax1.legend()\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}k'))\n",
    "\n",
    "# Plot 2: Actual vs Predicted\n",
    "ax2 = axes[1]\n",
    "y_pred = lr_model.predict(X_test)\n",
    "ax2.scatter(y_test, y_pred, alpha=0.7, c='teal', edgecolors='white', s=60)\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val = min(y_test.min(), y_pred.min())\n",
    "max_val = max(y_test.max(), y_pred.max())\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "\n",
    "ax2.set_xlabel('Actual Price ($)')\n",
    "ax2.set_ylabel('Predicted Price ($)')\n",
    "ax2.set_title('Actual vs Predicted (closer to line = better)')\n",
    "ax2.legend()\n",
    "ax2.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}k'))\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}k'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nR¬≤ Score: {r2_score(y_test, y_pred):.3f} (1.0 = perfect, 0 = useless)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-linreg-residuals-title",
   "metadata": {},
   "source": [
    "### Visualization 2: Residuals (The Errors)\n",
    "Residuals show where the model is wrong. Ideally, errors should be random‚Äîno pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-linreg-residuals",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residuals vs Predicted\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_pred, residuals, alpha=0.7, c='purple', edgecolors='white', s=60)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Predicted Price')\n",
    "ax1.set_ylabel('Residual (Error)')\n",
    "ax1.set_title('Residuals Plot: Random Scatter = Good Model')\n",
    "ax1.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}k'))\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}k'))\n",
    "\n",
    "# Histogram of residuals\n",
    "ax2 = axes[1]\n",
    "ax2.hist(residuals, bins=15, color='mediumpurple', edgecolor='white', alpha=0.8)\n",
    "ax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Residual (Error)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Residual Distribution: Should Be Centered at 0')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-linreg-failure-title",
   "metadata": {},
   "source": [
    "### Visualization 3: When Linear Regression Fails\n",
    "What happens when the data isn't actually linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-linreg-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-linear data (quadratic relationship)\n",
    "np.random.seed(42)\n",
    "x_nonlinear = np.linspace(0, 10, 100)\n",
    "y_nonlinear = 2 * x_nonlinear**2 - 5 * x_nonlinear + 10 + np.random.normal(0, 8, 100)\n",
    "\n",
    "# Fit linear regression to non-linear data\n",
    "lr_bad = LinearRegression()\n",
    "lr_bad.fit(x_nonlinear.reshape(-1, 1), y_nonlinear)\n",
    "y_bad_pred = lr_bad.predict(x_nonlinear.reshape(-1, 1))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Good fit (linear data)\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(X, y, alpha=0.5, c='steelblue', edgecolors='white')\n",
    "ax1.plot(x_line, y_line, 'green', linewidth=3, label='Linear Fit')\n",
    "ax1.set_title('‚úì Linear Data ‚Üí Linear Model Works!')\n",
    "ax1.set_xlabel('Square Footage')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.legend()\n",
    "\n",
    "# Bad fit (non-linear data)\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(x_nonlinear, y_nonlinear, alpha=0.5, c='coral', edgecolors='white')\n",
    "ax2.plot(x_nonlinear, y_bad_pred, 'red', linewidth=3, label='Linear Fit (Bad!)')\n",
    "ax2.set_title('‚úó Curved Data ‚Üí Linear Model Fails!')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Lesson: Linear Regression is like an Array‚Äîfast and simple, but only works for linear patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section2-title",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Decision Trees (The If/Else Block)\n",
    "\n",
    "**The Concept**: A flowchart that asks yes/no questions to classify data.\n",
    "\n",
    "**SWE Analogy**: A giant **nested if/else statement**. Highly readable, but can get overfit (too specific).\n",
    "\n",
    "Let's visualize how a tree \"thinks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-tree-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset (classic ML dataset)\n",
    "iris = load_iris()\n",
    "X_iris = iris.data[:, :2]  # Use only first 2 features for visualization\n",
    "y_iris = iris.target\n",
    "feature_names = iris.feature_names[:2]\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Split\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {len(X_iris)} flowers, {len(class_names)} species\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Classes: {list(class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-tree-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a small tree (max_depth=3 for readability)\n",
    "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_model.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "tree_preds = tree_model.predict(X_test_iris)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_score(y_test_iris, tree_preds):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-tree-viz-title",
   "metadata": {},
   "source": [
    "### Visualization 1: The Tree Structure\n",
    "This is literally the \"code\" the model learned‚Äîa series of if/else conditions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-tree-viz1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "plot_tree(\n",
    "    tree_model, \n",
    "    feature_names=feature_names, \n",
    "    class_names=class_names,\n",
    "    filled=True, \n",
    "    rounded=True,\n",
    "    ax=ax,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title('Decision Tree: Literally a Flowchart!', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Read it like code: 'IF petal width <= 0.8 THEN setosa, ELSE check petal length...'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-tree-boundary-title",
   "metadata": {},
   "source": [
    "### Visualization 2: Decision Boundaries\n",
    "This shows HOW the tree divides the feature space. Each color = a predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-tree-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, ax, title, class_names=None):\n",
    "    \"\"\"Helper function to plot decision boundaries\"\"\"\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "    cmap_bold = ['#FF0000', '#00FF00', '#0000FF']\n",
    "    \n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, 200),\n",
    "        np.linspace(y_min, y_max, 200)\n",
    "    )\n",
    "    \n",
    "    # Predict on mesh\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4, cmap=cmap_light)\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap=ListedColormap(cmap_bold), \n",
    "                         edgecolors='white', s=50, alpha=0.8)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    if class_names is not None:\n",
    "        handles = [plt.scatter([], [], c=cmap_bold[i], label=class_names[i], s=50) \n",
    "                   for i in range(len(class_names))]\n",
    "        ax.legend(handles=handles, loc='upper left')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# Plot decision boundary\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_decision_boundary(tree_model, X_iris, y_iris, ax, \n",
    "                      'Decision Tree Boundaries (max_depth=3)',\n",
    "                      class_names)\n",
    "ax.set_xlabel(feature_names[0])\n",
    "ax.set_ylabel(feature_names[1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice the RECTANGULAR boundaries‚Äîtrees only make axis-aligned splits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-tree-overfit-title",
   "metadata": {},
   "source": [
    "### Visualization 3: Overfitting Demo\n",
    "What happens when we remove the `max_depth` limit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-tree-overfit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train trees with different depths\n",
    "depths = [1, 3, 5, None]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "for ax, depth in zip(axes.flat, depths):\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    tree.fit(X_train_iris, y_train_iris)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train_iris, tree.predict(X_train_iris))\n",
    "    test_acc = accuracy_score(y_test_iris, tree.predict(X_test_iris))\n",
    "    \n",
    "    depth_str = str(depth) if depth else 'Unlimited'\n",
    "    title = f'max_depth={depth_str}\\nTrain: {train_acc:.1%} | Test: {test_acc:.1%}'\n",
    "    plot_decision_boundary(tree, X_iris, y_iris, ax, title)\n",
    "    ax.set_xlabel(feature_names[0])\n",
    "    ax.set_ylabel(feature_names[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è OVERFITTING: Unlimited depth = 100% training accuracy but worse test accuracy!\")\n",
    "print(\"The model memorized the training data instead of learning general patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section3-title",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Random Forests (The Distributed System)\n",
    "\n",
    "**The Concept**: Train 100 different trees on random subsets of data. Let them **vote**.\n",
    "\n",
    "**SWE Analogy**: Like **RAID** or **distributed consensus**‚Äîmany weak components become one reliable system.\n",
    "\n",
    "Let's see the \"wisdom of the crowd\" in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-rf-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "rf_model.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "rf_preds = rf_model.predict(X_test_iris)\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test_iris, rf_preds):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-rf-voting-title",
   "metadata": {},
   "source": [
    "### Visualization 1: How Trees Vote\n",
    "Each tree in the forest makes a prediction. The final answer = majority vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-rf-voting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from individual trees for a single sample\n",
    "sample_idx = 0\n",
    "sample = X_test_iris[sample_idx].reshape(1, -1)\n",
    "true_label = y_test_iris[sample_idx]\n",
    "\n",
    "# Get each tree's prediction\n",
    "individual_predictions = np.array([tree.predict(sample)[0] for tree in rf_model.estimators_])\n",
    "\n",
    "# Count votes\n",
    "vote_counts = [np.sum(individual_predictions == i) for i in range(3)]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of votes\n",
    "ax1 = axes[0]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "bars = ax1.bar(class_names, vote_counts, color=colors, edgecolor='white', linewidth=2)\n",
    "ax1.set_ylabel('Number of Trees')\n",
    "ax1.set_xlabel('Predicted Class')\n",
    "ax1.set_title(f'100 Trees Vote on Sample #{sample_idx}\\nTrue Label: {class_names[true_label]}')\n",
    "for bar, count in zip(bars, vote_counts):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{count}', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Show first 20 trees' individual votes\n",
    "ax2 = axes[1]\n",
    "first_20 = individual_predictions[:20]\n",
    "tree_colors = [colors[p] for p in first_20]\n",
    "ax2.bar(range(20), [1]*20, color=tree_colors, edgecolor='white')\n",
    "ax2.set_xlabel('Tree Index (first 20 of 100)')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('Each Bar = One Tree\\'s Vote')\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=colors[i], label=class_names[i]) for i in range(3)]\n",
    "ax2.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "final_pred = rf_model.predict(sample)[0]\n",
    "print(f\"\\nFinal Prediction: {class_names[final_pred]} (won with {max(vote_counts)} votes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-rf-boundary-title",
   "metadata": {},
   "source": [
    "### Visualization 2: Decision Boundary Comparison\n",
    "Compare single tree vs forest‚Äînotice how the forest is smoother?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-rf-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Single deep tree (prone to overfitting)\n",
    "single_tree = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "single_tree.fit(X_train_iris, y_train_iris)\n",
    "single_acc = accuracy_score(y_test_iris, single_tree.predict(X_test_iris))\n",
    "plot_decision_boundary(single_tree, X_iris, y_iris, axes[0], \n",
    "                      f'Single Tree (depth=10)\\nTest Accuracy: {single_acc:.1%}',\n",
    "                      class_names)\n",
    "\n",
    "# Random Forest (robust)\n",
    "rf_acc = accuracy_score(y_test_iris, rf_preds)\n",
    "plot_decision_boundary(rf_model, X_iris, y_iris, axes[1], \n",
    "                      f'Random Forest (100 trees)\\nTest Accuracy: {rf_acc:.1%}',\n",
    "                      class_names)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(feature_names[0])\n",
    "    ax.set_ylabel(feature_names[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: Single tree has jagged, overfit boundaries. Forest is smoother and more general.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-rf-importance-title",
   "metadata": {},
   "source": [
    "### Visualization 3: Feature Importance\n",
    "Random Forests can tell you WHICH features matter most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-rf-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on ALL features for better importance analysis\n",
    "rf_full = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_full.fit(iris.data, iris.target)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_full.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(importances)))\n",
    "bars = ax.barh(range(len(importances)), importances[indices], color=colors, edgecolor='white')\n",
    "ax.set_yticks(range(len(importances)))\n",
    "ax.set_yticklabels([iris.feature_names[i] for i in indices])\n",
    "ax.set_xlabel('Importance Score')\n",
    "ax.set_title('Feature Importance: Which Features Matter?')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add percentage labels\n",
    "for bar, imp in zip(bars, importances[indices]):\n",
    "    ax.text(imp + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "            f'{imp:.1%}', va='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop feature: {iris.feature_names[indices[0]]} ({importances[indices[0]]:.1%} importance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-section4-title",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. The Polymorphism of Scikit-Learn\n",
    "\n",
    "Notice how we never changed our evaluation code? That's the beauty of a consistent API.\n",
    "\n",
    "```python\n",
    "# The \"Interface\"\n",
    "class Model:\n",
    "    def fit(self, X, y): pass\n",
    "    def predict(self, X): pass\n",
    "```\n",
    "\n",
    "You can swap algorithms like swapping data structures‚Äîsame interface, different performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load digits dataset (from Chapter 2)\n",
    "digits = load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(\n",
    "    X_digits, y_digits, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define our \"zoo\" of models\n",
    "models = {\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Same code, different models!\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_d, y_train_d)  # Same interface\n",
    "    preds = model.predict(X_test_d)  # Same interface\n",
    "    accuracy = accuracy_score(y_test_d, preds)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name}: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-comparison-viz-title",
   "metadata": {},
   "source": [
    "### Final Visualization: Algorithm Showdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-comparison-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "names = list(results.keys())\n",
    "accuracies = list(results.values())\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "bars = ax.barh(names, accuracies, color=colors, edgecolor='white', height=0.6)\n",
    "ax.set_xlim(0.8, 1.0)\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_title('Algorithm Showdown: Digits Recognition', fontsize=14)\n",
    "\n",
    "# Add percentage labels\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    ax.text(acc + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "            f'{acc:.1%}', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add SWE analogy labels\n",
    "analogies = ['(HashMap lookup)', '(If/Else statements)', '(Distributed consensus)']\n",
    "for i, (bar, analogy) in enumerate(zip(bars, analogies)):\n",
    "    ax.text(0.81, bar.get_y() + bar.get_height()/2, \n",
    "            analogy, va='center', fontsize=9, style='italic', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "winner = max(results, key=results.get)\n",
    "print(f\"\\nüèÜ Winner: {winner} with {results[winner]:.1%} accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Your Algorithm Cheat Sheet\n",
    "\n",
    "| Algorithm | SWE Analogy | When to Use | Trade-off |\n",
    "|-----------|-------------|-------------|------------|\n",
    "| **Linear Regression** | Array | Additive relationships (Price = A√óSqFt + B) | Fast but rigid |\n",
    "| **Decision Tree** | If/Else | Need explainability (loan approval) | Interpretable but overfits |\n",
    "| **Random Forest** | RAID/Consensus | Default for tabular data | Robust but black-box |\n",
    "| **K-Nearest Neighbors** | HashMap lookup | When similar inputs ‚Üí similar outputs | Simple but slow at scale |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-challenge",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ú¶ Challenge\n",
    "\n",
    "1. Go back to the **Decision Tree overfitting demo**. What `max_depth` gives the best test accuracy?\n",
    "2. In the **Algorithm Showdown**, add `LogisticRegression` from `sklearn.linear_model`. How does it compare?\n",
    "3. Try changing `n_estimators` in Random Forest from 100 to 10. Does accuracy drop significantly?\n",
    "\n",
    "**Next Chapter**: We have multiple models‚Äîbut how do we *really* know which is best? Accuracy can lie. We'll explore **Evaluation Metrics**‚Äîthe unit tests of ML."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
