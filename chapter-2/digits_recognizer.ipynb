{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Episode 3: Your First Model (Digits Recognizer)\n",
                "\n",
                "This notebook accompanies Episode 3 of the SWE-to-MLE series.\n",
                "We will build a system to recognize handwritten digits."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. The Setup\n",
                "Importing the standard library of ML: Scikit-Learn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from sklearn import datasets\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.metrics import accuracy_score"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. The Data\n",
                "Loading the MNIST (Digits) dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "digits = datasets.load_digits()\n",
                "\n",
                "# X = The features (pixel data)\n",
                "# y = The labels (the number 0-9)\n",
                "X, y = digits.data, digits.target\n",
                "\n",
                "print(f\"Dataset Shape: {X.shape}\")\n",
                "print(f\"We have {X.shape[0]} images, each with {X.shape[1]} pixels (8x8 grid).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Let's see the examples!\n",
                "You can't code blindly. Let's look at what the computer sees."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
                "for ax, image, label in zip(axes, digits.images, digits.target):\n",
                "    ax.set_axis_off()\n",
                "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
                "    ax.set_title(f\"Label: {label}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. The Split\n",
                "Separate training data (study guide) from test data (final exam)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "print(f\"Training examples: {len(X_train)}\")\n",
                "print(f\"Test examples: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. The Model (Training)\n",
                "We use K-Nearest Neighbors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = KNeighborsClassifier(n_neighbors=3)\n",
                "model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Prediction & Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = model.predict(X_test)\n",
                "\n",
                "accuracy = accuracy_score(y_test, predictions)\n",
                "print(f\"Accuracy: {accuracy:.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sanity Check\n",
                "Let's visualize a few predictions to see where it succeeds (or fails)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
                "for ax, image, prediction, true_label in zip(axes, X_test[:4].reshape(-1, 8, 8), predictions[:4], y_test[:4]):\n",
                "    ax.set_axis_off()\n",
                "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
                "    ax.set_title(f\"Pred: {prediction} (True: {true_label})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Where it failed\n",
                "Even a 98% accurate model makes mistakes. Looking at failures is how we improve."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# Find the indices where predictions don't match the truth\n",
                "failed_indices = np.where(predictions != y_test)[0]\n",
                "\n",
                "print(f\"Total failures: {len(failed_indices)} out of {len(y_test)}\")\n",
                "\n",
                "if len(failed_indices) > 0:\n",
                "    num_to_show = min(4, len(failed_indices))\n",
                "    _, axes = plt.subplots(nrows=1, ncols=num_to_show, figsize=(10, 3))\n",
                "    # Wrap axes in a list if only one subplot is created\n",
                "    if num_to_show == 1: axes = [axes]\n",
                "    \n",
                "    for ax, idx in zip(axes, failed_indices[:num_to_show]):\n",
                "        ax.set_axis_off()\n",
                "        image = X_test[idx].reshape(8, 8)\n",
                "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
                "        ax.set_title(f\"Pred: {predictions[idx]}\\nTrue: {y_test[idx]}\")\n",
                "else:\n",
                "    print(\"Zero failures! The model was perfect on this test set.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Your Turn: The Challenge\n",
                "\n",
                "1. Go back to **Section 4** and change `n_neighbors=3` to `n_neighbors=1`.\n",
                "2. Re-run the training and evaluation cells. Does accuracy go up or down?\n",
                "3. Why do you think that is?\n",
                "\n",
                "**Experimental Mindset:** In ML, we don't just write code; we run experiments. Changing these settings (called **Hyperparameters**) is how we find the best version of our model."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}